This is a log to keep track of the advances in the study (so that I won't forget).
It is mostly intuitive explanation of the hurdles, solutions, debuggings, etc.
It is initiated on Aug 7 2024.

Current TO-DOs:

	1. Correction Detection function should be coded using the error signals obtained in the MPC loop.
	Among the signals, tau_ext and trajectory error show bigger potential, hence higher priority should be assumed.
	
	2. 

Before Aug 7 2024:
	
	- The simulation of Kuka in Mujoco is done and working
	- The simulation allows for manual and coded purturbations of the robot in realtime
	- The MPC is governing the control of the robot in reaching task w/ obstacle avoidance 
	starting from (0.35, -0.4, 0.4) towards the goal at (0.45, 0.4, 0.6).
	There are 3 obstacles:
		1. [0.450, -0.15, 0.4]
		2. [0.450, 0.0, 0.5]
		3. [0.450, 0.15, 0.6]
	
	- There are 3 collision pairs added to the geometry model for cost assignment. 
	The collision pairs are:
		1. Last link of the robot (A7) to Obstacle 1
		2. Last link of the robot (A7) to Obstacle 2
		3. Last link of the robot (A7) to Obstacle 3
	
	- The geometry model itself is improved to better represent the body of the robot for collision analysis.
	Before, the model was being defined with a Capsule (defined in hppfcl library) of 50 cm length and ZERO radius for each link.
	Now, the model has capsules for each link with R = 4 cm and link length equal to the link length in the robot.
	Link lengths are derived from Kuka specifications: {0.36, 0, 0.42, 0, 0.4, 0, 0.126}
	
	- Collision pair definition was changed from defining with entries of (robot_link, obstacle) ----to---> (obstacle, robot_link)
	This change is due to the fact that in Crocoddyl, when the cost function is trying to compute the calcDiff (for Cost derivatives)
	it chooses the first entry of the collision pair to compare against the task-space position of the joint_id (EE in this case) that we are trying to keep away from the obstacle.
	Hence, putting the obstacle as first entry in the collision pair definition is more accurate.
	
	- For "correction" detection, I tried several signals:
		1. tau_ext = (M*q_ddot + b) - u_curr --> q_ddot is computed numerically in MPC loop
		2. Goal Error: This signal is defined by the squared error between the "intended MPC goal state/EE positions" and "actual state/EE position" at time t
		3. Trajectory Error: This is the norm of error between the "intended MPC trajectory for state/EE positions" and "tracked state/EE positions" by the robot during the past MPC horizon
		4. Kinematic and Potential Energy: derived from Pinocchio
	All these signals have some contribution to understanding when the robot is being purturbed (corrected).
	Perhaps the final decision would be to have a weighted sum of all these signals and look at the spikes and rates of change in the final signal to indicate the correction.
	At the moment, I assume we know when the correction has taken place.
	
	- An online weight changing function is written.
	Turns out that we can modify the feature costs online and see the MPC react to this change (it is tested successfully). 
	The assumption was that the feature should be removed from the cost model and then re-added with a different weight, but now with a simple function we can alter it on the go.
	--> Code line --> solver.problem.terminalModel.differential.costs.costs[cost_number].weight = new_weight
	
	- A CostModel class is defined to poll the cost at each instance upon demand.
	For this purpose there are several data collector variables defined so that the costs are calculated (using "calc" and "calcDiff") separately and altogether.
	The defiitions for data collectors in may vary based on the feature types. The defining functions for this project are:
		1. State Cost Regularization: 
		2. Control Cost Regularization: 
		3. Translation Cost:
		4. Collision Cost:
	There is still an issue with the sum of the trajectory cost (generated by MPC) using the CostStack class, and the cost that the solver reports.
	
Aug 7 2024:

	- The weights are separated to two different variables for "running" and "terminal" costs.
	
	- The issue with the CostStack class might be due to the underlying variables that are defining the OCP problem and Cost class simultaneously. 
	I have created two different entities for defining the solver (for MPC) and cost class (for IRL computations) separately so that they do not interfere.
	
	- I have updated the effort above to create two separate solvers for identical shooting problems.
	The costs and the weights for each cost can be retrieved from the solver instance directly as follows:
	For a particular cost for translation:
		For Terminal Cost: solver.problem.terminalData.differential.costs.costs['terminal_translation'].cost
		For Terminal Weight: dummy_solver.problem.terminalModel.differential.costs.costs['terminal_translation'].weight
		For Running Cost: solver.problem.runningDatas[i].differential.costs.costs['running_translation'].cost
		For Running Weight: solver.problem.runningModels[i].differential.costs.costs['running_translation'].weight
	Now I can have the weighted cost per state/control instance throughout the trajectories solved by MPC
	
	TO-DO: I need to work further on the Cost computation class as there is a need for numerical computation of X and U trajectory costs that are different from MPC generations
	

Aug 8 2024:

	- Three methods of cost evaluation are being investigated and compared towards getting a consistent cost computation model for the study.
	This is needed for IRL evaluations in the middle of the MPC loops.
	These methods are:
		1. Getting the final cost from the solver: solver.cost
		2. Getting the final cost by calculating the weighted sum the cost of each cost_model defined in the process of OCP definition.
		This means that the cost features and weights were directly polled from the Crocoddyl model:
		features: --> solver.problem.terminalData.differential.costs.costs[cost_feat].cost
		weights: --> solver.problem.terminalModel.differential.costs.costs[cost_feat].weight
		3. Getting the final cost by manually (brute-force) computing the cost using "calc" and "calcDiff" functions of each and every cost_model and computing the weighted sum.
		
	So far, all three have similar but different results:
	Solver Cost:  3.53142 || Computed Sum Cost:  3.82521 || Numerical Cost:  3.70283

	- Three different solvers were created for the cause mentioned above. Although they solved separate (identical) problems, the cost discrepency was still there.
	Exploring why...
	
	- SOLVED: The issue between the first and second method's mismatch was due to the fact that the running models' cost were not being multiplied by the time difference (dt),
	so the integration was not being done properly. Now, the only mismatch is between the 2nd and 3rd method which is now significantly lower than before:
	Solver Cost:  3.53142 || Computed Sum Cost:  3.53142 || Numerical Cost:  3.54379
	
	- At this point I think I'm fine. I'll just use the inner-computed costs for each instance within the CostData and CostModel.
	IMPORTANT NOTE: Should use the .copy() command before doing any computation !! 
	Example: A = solver.problem.terminalData.differential***.copy()***.cost 
	
	TO-DO: Forget the previously written CostStack functions. 
	Create two separate solver(problem)s, use one for the MPC loop and it's Xs and Us generations, and the other for reward analysis, and sampled trajectory analysis around the generated
	trajectories. 
	
Aug 9 2024:

	- 











	
	
